# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18VKEN_yv1m6ApWxOGbOimsI8tpw7BoGI

### Melbourne Open Data
<div class="Melbourne Open Data - Business Establishments">
  <i>Dataset:</i> Business establishments location and industry classification 374210 records
  <br>
  <a href="https://data.melbourne.vic.gov.au/explore/dataset/business-establishments-with-address-and-industry-classification/information/" target="_blank">Dataset Link</a>
</div>

##### Open Data is provided under a creative commons licence
- Free to share, adapt data for any purpose as long as credit is given to Melbourne City Council
"""

#Libraries
!pip -q install requests

from io import StringIO
import requests

from google.colab import drive
drive.mount('/content/drive')

#load libraries
import os
import warnings
warnings.filterwarnings('ignore')
import requests
from urllib.request import urlopen
import json
from tqdm import tqdm

import warnings
warnings.filterwarnings("ignore")

!pip install tqdm # Progress bar
!pip install osmnx

# Download datasets
def download_dataset(dataset_id, base_url='https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/'):
    format = 'csv'
    url = f'{base_url}{dataset_id}/exports/{format}'
    params = {
        'select': '*',
        'limit': -1,  # all records
        'lang': 'en',
        'timezone': 'UTC'
    }

    with requests.get(url, params=params, stream=True) as response:
        if response.status_code == 200:
            total_size = int(response.headers.get('content-length', 0))
            chunk_size = 1024  # 1KB per chunk
            progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True, desc=f"Downloading {dataset_id}")

            content = bytearray()
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:  # filter out keep-alive new chunks
                    content.extend(chunk)
                    progress_bar.update(len(chunk))

            progress_bar.close()
            data = pd.read_csv(StringIO(content.decode('utf-8')), delimiter=';')
            return data
        else:
            print(f'Request failed with status code {response.status_code}')
            return None

# Dataset IDs
dataset_ids = [
    'business-establishments-with-address-and-industry-classification'
]

datasets = {}
for dataset_id in dataset_ids:
    datasets[dataset_id] = download_dataset(dataset_id)
    if datasets[dataset_id] is not None:
        print(f"{dataset_id} downloaded successfully.")

datasets['business-establishments-with-address-and-industry-classification'].head()

shape_of_dataset = datasets['business-establishments-with-address-and-industry-classification'].shape
print(shape_of_dataset)

# Save
base_path = '/content/drive/My Drive/sit323'

for dataset_id, df in datasets.items():
    if df is not None:
        filename = f"{base_path}{dataset_id}.csv"
        df.to_csv(filename, index=False)
        print(f"Saved {filename} to Google Drive.")